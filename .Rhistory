temp <- comData$VAL == 24
class(temp)
summary(temp)
comData$FES
temp <- comData$VAL[comData$VAL==24]
temp <- !is.na(temp)
length(temp)
temp
summary(temp)
length(temp == TRUE)
setkey(comData, VAL)
temp <- comData$VAL[comData$VAL==24 & !is.na(comData$VAL)]
lengh(temp)
length(temp)
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileURL,".\\data\ngap.xlsx")
download.file(fileURL,".\\data\\ngap.xlsx")
library(xlsx)
library("xlsx")
install.packages("XLSX")
library(xlsx)
library("xlsx")
install.packages("XLSX")
install.packages("xlsx")
library("xlsx")
install.packages("rjava")
install.packages("rJava")
library("xlsx")
library("rJava")
install.packages("xlsx")
install.packages("rJava")
install.packages(rJava)
R.Version
R.Version()
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
Sys.getenv("JAVA_HOME")
library(rJava)
library(rJava)
library(xlsx)
rows <- 18:23
cols <- 7:15
xlsdat <- read.xlsx(".\\data\ngap.xlsx", 1, colIndex = cols, rowIndex = rows)
xlsdat <- read.xlsx(".\\data\\ngap.xlsx", 1, colIndex = cols, rowIndex = rows)
download.file(fileURL,".\\data\gap.xlsx",mode='wb')
download.file(fileURL,".\\data\\gap.xlsx",mode='wb')
xlsdat <- read.xlsx(".\\data\\gap.xlsx", 1, colIndex = cols, rowIndex = rows)
head(xlsdat)
sum(xlsdat$Zip*xlsdat$Ext,na.rm=T)
rm(list=ls())
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
library(xml)
install.packages("xml")
install.packages("XML")
library("XML")
docm <- xmlTreeParse(fileURL,useInternal=TRUE)
docm <- xmlTreeParse(fileURL,useInternalNodes = TRUE)
rm(list=ls())
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
docm <- xmlTreeParse(fileURL,useInternal=TRUE)
xData <- getURL(fileURL)
library(XML)
xData <- getURL(fileURL)
library(curl)
xData <- getURL(fileURL)
library(Rcurl)
install.packages("Rcurl")
install.packages("RCurl")
library(RCurl)
xData <- getURL(fileURL)
doc <- xmlParse(xData)
class(doc)
rootNode <- xmlRoot(doc)
rootNode
xmlName(rootNode)
names(rootNode)
rootnote[[1]]
rootNode[[1]]
rootNode[[1][1]]
rootNode[[1]][[1]]
rootNode[[1]][[1]]
sum(xpathSApply(rootNode, "//zipcode", xmlValue) == "21231")
rm(list=ls())
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
csData <- read.csv(fileURL)
head(csData)
DT <- fread(fileURL)
install.packages("fread")
download.file(fileUrl, destfile = "./data/06pid.csv", method = "curl")
download.file(fileURL, destfile = ".\\data\\06pid.csv", method = "curl")
download.file(fileURL, destfile = ".\\data\\06pid.csv")
DT <- fread(".\\data\\06pid.csv")
getAnywhere(fread)
?fread
library(data.table)
install.packages("data.table")
library(data.table)
DT <- fread(".\\data\\06pid.csv")
mean(DT$pwgtp15,by=DT$SEX)
DT[,mean(pwgtp15),by=SEX]
sapply(split(DT$pwgtp15,DT$SEX),mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
tapply(DT$pwgtp15,DT$SEX,mean)
rm(list=ls())
quit()
library(swirl)
swirl()
mydf <- read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:30
5:20
select(cran,r_arch:country)
select(cran,country:r_arch)
cran
select(rcanm -time)
select(rcan, -time)
select(cran, -time)
select(cran,-5:20)
-5:20
-[5:20]
[5:20]-
[-5]:[-20]
{-5}:{-20}
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version >= "3.0.2", country IN "India")
filter(cran, r_version >= "3.0.2", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500 & r_os ="linux-gnu")
filter(cran, size > 100500 & r_os =="linux-gnu")
filter(cran, size > 100500, r_os =="linux-gnu")
is.na(c(3, 5, NA, 10)).
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2  <- select(cran, size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2,package,ip_id)
arrange(cran2,country, desc(r_version),ip_id)
cran3 <-select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_gb = size_mb / 2^10)
cran3
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size-1000)
mutate(cran3, correct_size = size+1000)
summarise(cran,avb_bytes = mean(size))
summarise(cran,avg_bytes = mean(size))
summarize(cran,avg_bytes = mean(size))
quit()
library(swirl)
swirl
swirl()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran,package)
by_package
mean(by_package)
summarize(by_package,mean(size))
library(swirl)
swirl()
submit()
?n
?n_distinct
submit()
submit()
tbl
info()
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(pack_sum,count>679)
top_counts <- (pack_sum, count > 679)
top_counts <-filter(pack_sum,count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
view(top_counts_sorted)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
filter(pack_sum,unique>465)
filter(pack_sum, unique > 465)
top_unique <- filter(pack_sum, unique > 465)
view(top_unique)
View(top_unique)
View(top_unique,desc(unique))
arrange(top_unique, desc(unique))
top_counts_sorted <- arrange(top_unique, desc(unique))
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
view(results3)
View(results3)
View(result3)
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
quit()
info
info()
bye()
swirl()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
res<-gather(students2,sex_class,count,-grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
submit()
students3
submit()
?spread
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()-
id, name, and sex
submit()
submit()
passed
failed
mutate(passed,status="passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
?bind_rows
bind_rows(passed,failed)
sat
submit()
submit()
submit()
submit()
rm(lists=ls())
rm(list=ls())
library(jpeg)
install.packages(jpeg)
install.packages("jpeg")
install.packages("data.table")
install.packages("dplyr")
install.packages("dplyr")
install.packages("Hmisc")
library(jpeg)
library(data.table)
library(dplyr)
library(Hmisc)
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
dst1 = 'q1.csv'
dst1 = 'E:\\1_data\\course3_week3\\data1.csv'
download.file(fileurl1, dst1, method = 'curl')
dst1 = 'E:\\data\\course3_week3\\data1.csv'
download.file(fileurl1, dst1, method = 'curl')
dst1 = 'E://data//course3_week3//data1.csv'
download.file(fileurl1, dst1, method = 'curl')
dst1 = 'data1.csv'
download.file(fileurl1, dst1, method = 'curl')
dst1 = 'data//c3_week3.csv'
download.file(fileurl1, dst1, method = 'curl')
download.file(fileurl1, dst1)
data1 = read.csv(dst1)
head(data1)
agricultureLogical = data1$ACR == 3 & data1$AGS == 6
agricultureLogical
head(which(agricultureLogical), 3)
fileurl2 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg'
dst2 = '//data/C3_week3_q2.jpg'
download.file(fileurl2, dst2, mode = 'wb')
dst2 = '//data//C3_week3_q2.jpg'
download.file(fileurl2, dst2, mode = 'wb')
pwd
pwd()
getwd()
dst2 = '\\data\\C3_week3_q2.jpg'
download.file(fileurl2, dst2, mode = 'wb')
dst2 = 'data//C3_week3_q2.jpg'
download.file(fileurl2, dst2, mode = 'wb')
data2 = readJPEG(dst2, native = TRUE)
quantile(data2, probs = c(0.3, 0.8))
rm(list=ls())
fileurl3a = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst3a = 'data//c3_Week3_q3a.csv'
fileurl3b = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
dst3b = 'data//c3_Week3_q3b.csv'
download.file(fileurl3a, dst3a)
download.file(fileurl3b, dst3b)
gdp = fread(dst3a, skip=4, nrows = 190, select = c(1, 2, 4, 5), col.names=c("CountryCode", "Rank", "Economy", "Total"))
download.file(fileurl3a, dst3a, mode = 'wb')
download.file(fileurl3b, dst3b,mode='wb')
gdp = fread(dst3a, skip=4, nrows = 190, select = c(1, 2, 4, 5), col.names=c("CountryCode", "Rank", "Economy", "Total"))
gdo
gdp
gdp
edu = fread(dst3b)
edu
merge = merge(gdp, edu, by = 'CountryCode')
merge
nrow(merge)
arrange(merge, desc(Rank))[13, Economy]
nrow(merge)
tapply(merge$Rank, merge$`Income Group`, mean)
merge$RankGroups <- cut2(merge$Rank, g=5)
table(merge$RankGroups, merge$`Income Group`)
rm(list=ls())
swirl()
swril()
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day,label = TRUE)
this_moment <- now()
this_moment
second(this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("192012//")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment,hours=15, minute=38)
this_moment <- update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
nyc <- now("America/New_York")
byc
nyc
depart <- byc+days(2)
depart <- nyc+days(2)
depart
depart <- update(nyc,hours=17, minutes=34)
depart <- update(depart,hours=17, minutes=34)
depart
arrive <- depart+hours(15)+minutes(50)
?with_tz
arrive <- with_tz(arrive,tzone="Asia/Hong_kong")
arrive <- with_tz(arrive,"Asia/Hong_kong")
arrive <- with_tz(arrive,"Asia/Hong_Kong")
arrive
last_time<- mdy("June 17, 2008",tz="Singapore")
last_time
?new_interval
how_long <- new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
rm(list=ls())
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
dest <- "data\\c3_week4_ss06hid.csv"
download.file(url, dest)
dt <- data.table(read.csv(dest))
varNames <- names(dt)
varNamesSplit <- strsplit(varNames, "wgtp")
varNamesSplit[[123]]
varNames
?strsplit
varNamesSplit
head(varNamesSplit)
rm(list=ls())
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
dest <- "data\C3_week4_GDP.csv"
dest <- "data\\C3_week4_GDP.csv"
download.file(url, f)
download.file(url, dest)
dtGDP <- data.table(read.csv(dest, skip = 4, nrows = 215, stringsAsFactors = FALSE))
dtGDP
dtGDP <- dtGDP[X != ""]
dtGDP
dtGDP <- dtGDP[, list(X, X.1, X.3, X.4)]
dtGDP
setnames(dtGDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "gdp"))
dtGDP
gdp <- as.numeric(gsub(",", "", dtGDP$gdp))
dtGDP
mean(gdp,na.rm = TRUE)
isUnited <- grepl("^United", dtGDP$Long.Name)
summary(isUnited)
rm(list-ls())
rm(list=ls())
getwd()
setwd("/Tidyproject")
setwd("//Tidyproject")
setwd("\\Tidyproject")
setwd("e:\\Rstudio_working\\Tidyproject")
getwd()
featureNames <- read.table("\\data\\features.txt")
featureNames <- read.table(".\\data\\features.txt")
featureNames
activityLabels <- read.table(".\\data\\activity_labels.txt", header = FALSE)
activityLabels
subjectTrain <- read.table(".\\data\\train\\subject_train.txt", header = FALSE)
activityTrain <- read.table(".\\data\\train\\y_train.txt", header = FALSE)
featuresTrain <- read.table(".\\data\\train\\X_train.txt", header = FALSE)
subjectTrain
head(subjectTrain)
head(featureNames)
head(featureNames)
head(featuresTrain)
head(subjectTrain)
subjectTest <- read.table(".\\data\\test\\subject_test.txt", header = FALSE)
head(subjectTest)
activityTest <- read.table(".\\data\\test\\y_test.txt", header = FALSE)
featuresTest <- read.table(".\\data\\test\\X_test.txt", header = FALSE)
subject <- rbind(subjectTrain, subjectTest)
head(subject)
subject
activity <- rbind(activityTrain, activityTest)
head(activity)
summary(activity)
tail(activity)
features <- rbind(featuresTrain, featuresTest)
head(features)
summary(features)
colnames(features) <- t(featureNames[2])
names(features)
colnames(activity) <- "Activity"
colnames(subject) <- "Subject"
completeData <- cbind(features,activity,subject)
completeData
head(compelteData)
head(completeData)
summary(completeData)
columnsWithMeanSTD <- grep(".*Mean.*|.*Std.*", names(completeData), ignore.case=TRUE)
columnsWithMeanSTD
requiredColumns <- c(columnsWithMeanSTD, 562, 563)
requiredColumns
dim(completeData)
extractedData <- completeData[,requiredColumns]
dim(extractedData)
head(extractedData)
extractedData$Activity <- as.character(extractedData$Activity)
extractedData$Activity
for (i in 1:6){
extractedData$Activity[extractedData$Activity == i] <- as.character(activityLabels[i,2])
}
for (i in 1:6){  extractedData$Activity[extractedData$Activity == i] <- as.character(activityLabels[i,2]) }
extractedData$Activity <- as.factor(extractedData$Activity)
extractedData$Activity
names(extractedData)
names(extractedData)<-gsub("Acc", "Accelerometer", names(extractedData))
names(extractedData)<-gsub("Acc", "Accelerometer", names(extractedData))
names(extractedData)<-gsub("Gyro", "Gyroscope", names(extractedData))
names(extractedData)<-gsub("BodyBody", "Body", names(extractedData))
names(extractedData)<-gsub("Mag", "Magnitude", names(extractedData))
names(extractedData)<-gsub("^t", "Time", names(extractedData))
names(extractedData)<-gsub("^f", "Frequency", names(extractedData))
names(extractedData)<-gsub("tBody", "TimeBody", names(extractedData))
names(extractedData)<-gsub("-mean()", "Mean", names(extractedData), ignore.case = TRUE)
names(extractedData)<-gsub("-std()", "STD", names(extractedData), ignore.case = TRUE)
names(extractedData)<-gsub("-freq()", "Frequency", names(extractedData), ignore.case = TRUE)
names(extractedData)<-gsub("angle", "Angle", names(extractedData))
names(extractedData)<-gsub("gravity", "Gravity", names(extractedData))
names(extractedData)
extractedData$Subject <- as.factor(extractedData$Subject)
extractedData$Subject
extractedData <- data.table(extractedData)
extractedData
tidyData <- aggregate(. ~Subject + Activity, extractedData, mean)
tidyData <- tidyData[order(tidyData$Subject,tidyData$Activity),]
tidyData
write.table(tidyData, file = "Tidy.txt", row.names = FALSE)
names(tidyData)
write.table(tidyData, file = "Tidy.txt", row.names = FALSE)
